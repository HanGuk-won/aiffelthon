{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c3b2da",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "Implement of [Gozsoy's Conditionval VAE code(github)](https://github.com/gozsoy/conditional-vae).\n",
    "Originaly I imported [Elmisis's VAE code(github)](https://github.com/EleMisi/ConditionalVAE/) to make this [example](https://github.com/chhyyi/rz_cvae) but loss diverges. Also input of attributes(or conditioned input) are not efficient so I found another codes.   \n",
    "\n",
    "As team decided not to solve this problem cuz deadline of Aiffelthon is DEC 13, there will be no discussion about diverging loss.  \n",
    "\n",
    "I'll change only some lines of [cvae_example](https://github.com/chhyyi/rz_cvae/blob/main/cvae_expamle.ipynb) and python scripts (actually many part of gozsoy's code is hard coded but I'm not gonna fix that)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf0325",
   "metadata": {},
   "source": [
    "# Some test\n",
    "1. input parameter of conditional_encoder2 is hard-coded. So I'd better test this one.\n",
    "2. I think this is  all I need then   \n",
    "\n",
    "```python  \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    beta = 1e-11\n",
    "    epochs = 10\n",
    "    latent_dim = 15\n",
    "\n",
    "    train_ds,dataset_mean,dataset_std = prepare_data()\n",
    "\n",
    "    model,z_mu_list,label_list = train(latent_dim,beta,epochs,train_ds,dataset_mean,dataset_std)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6404cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gozsoy_src.model as gmodel\n",
    "import gozsoy_src.main as gmain\n",
    "import gozsoy_src.utils as gutils\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb52cb4",
   "metadata": {},
   "source": [
    "# copy of cvae_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7404335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "import pandas as pd\n",
    "list_attr_path = \"list_attr.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4073be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images id and attributes...\n",
      "img_ids: 1513 \n",
      "Attributes: 26 \n",
      "\n",
      "Splitting dataset...\n",
      "\n",
      "Train set dimension: 1513 \n",
      "Test set dimension: 0 \n",
      "\n",
      "<class 'dict'>\n",
      "Test data successfully saved.\n"
     ]
    }
   ],
   "source": [
    "import gozsoy_src.model as gmodel\n",
    "import gozsoy_src.main as gmain\n",
    "import gozsoy_src.utils as gutils\n",
    "\n",
    "import tensorflow as tf\n",
    "import rz_cvae.Dataset as Dataset\n",
    "from rz_cvae.utils import save_data\n",
    "from gozsoy_src.model import Conditional_VAE\n",
    "\n",
    "learning_rate = 0.001\n",
    "train_size = 1.0\n",
    "batch_size = 4\n",
    "save_test_set = True\n",
    "# S# True: the test set image IDs and other useful information will be stored in a pickle file to further uses (e.g. Image_Generation.ipynb) \n",
    "\n",
    "dataset = Dataset.Dataset(train_size = train_size,batch_size = batch_size,save_test_set = save_test_set)\n",
    "label_dim = 26\n",
    "image_dim = [4, 1024, 1024, 6]\n",
    "latent_dim = 128\n",
    "\n",
    "\n",
    "# Model\n",
    "model = gmodel.Conditional_VAE(latent_dim)\n",
    "\n",
    "# Optiizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c174833",
   "metadata": {},
   "source": [
    "## set checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9869ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Checkpoint path\n",
    "checkpoint_root = \"./CVAE_gozsoy_{}_{}\".format(latent_dim, train_size) \n",
    "checkpoint_name = \"model\"\n",
    "save_prefix = os.path.join(checkpoint_root, checkpoint_name)\n",
    "\n",
    "# Define the checkpoint\n",
    "checkpoint = tf.train.Checkpoint(module=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdde03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 20,  number of batches: 378\n",
      "IDs shuffled.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from rz_cvae.utils import train_step\n",
    "\n",
    "beta = 1e-4 #it was too low... but why?? Still I don't understand KL loss.\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "train_recon_errors = []\n",
    "train_latent_losses = []\n",
    "loss = []\n",
    "reconstruct_loss = []\n",
    "latent_loss = []\n",
    "\n",
    "step_index = 0\n",
    "n_batches = int(dataset.train_size / batch_size)\n",
    "n_epochs = 20\n",
    "\n",
    "print(\"Number of epochs: {},  number of batches: {}\".format(n_epochs, n_batches))\n",
    "\n",
    "# Epochs Loop\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.perf_counter()\n",
    "    dataset.shuffle() # Shuffling\n",
    "\n",
    "    # Train Step Loop\n",
    "    for step_index, inputs in enumerate(dataset):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # forward pass\n",
    "            z_mu,z_rho,decoded_imgs = model(inputs[0],inputs[1])\n",
    "\n",
    "            # compute loss\n",
    "            mse,kl = gmain.elbo(z_mu,z_rho,decoded_imgs,inputs[0])\n",
    "            total_loss = mse + beta * kl\n",
    "\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(total_loss,model.variables)\n",
    "\n",
    "        # update weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.variables))\n",
    "\n",
    "        # compute loss\n",
    "        train_losses.append(total_loss)\n",
    "        train_recon_errors.append(mse)\n",
    "        train_latent_losses.append(kl)\n",
    "\n",
    "        if step_index + 1 == n_batches:\n",
    "            break\n",
    "\n",
    "    loss.append(np.mean(train_losses, 0))\n",
    "    reconstruct_loss.append(np.mean(train_recon_errors, 0))\n",
    "    latent_loss.append(np.mean(train_latent_losses, 0))\n",
    "\n",
    "    exec_time = time.perf_counter() - start_time\n",
    "    print(\"Execution time: %0.3f \\t Epoch %i: loss %0.4f | reconstr loss %0.4f | latent loss %0.4f\"\n",
    "                        % (exec_time, epoch, loss[epoch], reconstruct_loss[epoch], latent_loss[epoch])) \n",
    "\n",
    "    if np.isnan([loss[-1], reconstruct_loss[-1], latent_loss[-1]]).any():\n",
    "        print(\"loss diverged. stop training\")\n",
    "        break\n",
    "    \n",
    "    # Save progress every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint.save(save_prefix + \"_\" + str(epoch + 1))\n",
    "        print(\"Model saved:\", save_prefix)\n",
    "\n",
    "# Save the final model                \n",
    "checkpoint.save(save_prefix)\n",
    "print(\"Model saved:\", save_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.restore(os.path.join(checkpoint_root,'model_30-6'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985baae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from rz_cvae.utils import batch_generator, convert_batch_to_image_grid, read_data\n",
    "\n",
    "# Read test_data.pickle \n",
    "test_data = read_data(\"./test_data\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = batch_generator(test_data['batch_size'], test_data['train_img_ids'], model_name = 'Conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8691d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Reconstructs and plots a bacth of test images.\n",
    "\"\"\"\n",
    "\n",
    "inputs = next(batch_gen)\n",
    "images=inputs[0]\n",
    "_, _, pred_img= model(inputs[0], inputs[1])\n",
    "\n",
    "#pred_img=(pred_img-np.min(pred_img))/(np.max(pred_img)-np.min(pred_img))\n",
    "\n",
    "#print(test_data[''])\n",
    "\n",
    "f = plt.figure(figsize=(24,60))\n",
    "ax = f.add_subplot(1,2,1)\n",
    "ax.imshow(convert_batch_to_image_grid(images))\n",
    "plt.axis('off')\n",
    "\n",
    "ax = f.add_subplot(1,2,2)\n",
    "ax.imshow(convert_batch_to_image_grid(pred_img.numpy()))\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "save_path = False\n",
    "if save_path :\n",
    "    plt.savefig(save_path + \"reconstruction.png\")\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "print(\"Reconstruction of a batch of test set images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36fa65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(pred_img), np.min(pred_img))\n",
    "pred_img=(pred_img-np.min(pred_img))/(np.max(pred_img)-np.min(pred_img))\n",
    "print(np.max(pred_img), np.min(pred_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290553b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x.split('/')[-1] for x in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ad1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, paths = next(batch_gen)\n",
    "_, _, pred_img= model(images, labels)\n",
    "\n",
    "#print(test_data[''])\n",
    "\n",
    "f = plt.figure(figsize=(24,60))\n",
    "ax = f.add_subplot(1,2,1)\n",
    "ax.imshow(convert_batch_to_image_grid(images))\n",
    "plt.axis('off')\n",
    "\n",
    "ax = f.add_subplot(1,2,2)\n",
    "ax.imshow(convert_batch_to_image_grid(pred_img.numpy()))\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "save_path = False\n",
    "if save_path :\n",
    "    plt.savefig(save_path + \"reconstruction.png\")\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "print(\"Reconstruction of a batch of test set images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f8d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x.split('/')[-1] for x in paths])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
